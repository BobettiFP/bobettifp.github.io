title: "LLaMA: Open and Efficient Foundation Language Models"
layout: single
date: 2025-08-22 10:00:00 -0400
categories: [Literature-Review]
tags: [Process Mining, LLM, GPT-4, Bard, DFG, Object-Centric, Declarative, Procedural, Fairness, pm4py]
author_profile: true

## TL;DR
이 기술보고서는 **프로세스 마이닝 산출물(DFG, 이벤트 로그, 프로세스 모델 등)을 텍스트로 추상화**해 LLM이 이해·추론하도록 하고, **직답(Direct), 다중 프롬프트(Multi-prompt), DB 쿼리 생성** 세 전략으로 질의·검증하는 방법을 실험한다. GPT-4와 Bard는 **절차적/선언적 모델을 꽤 잘 해석**했고, **오브젝트 중심 프로세스 마이닝**에서도 강점을 보였으며, **공정성(fairness) 평가**에도 잠재력이 확인됐다.

## 서지 정보
- Title: *Leveraging Large Language Models (LLMs) for Process Mining (Technical Report)*
- Authors: Alessandro Berti, Mahnaz Sadat Qafari  
- arXiv: 2307.12701 (v1), 2023-07-24

## 문제 정의
프로세스 마이닝의 핵심 산출물(이벤트 로그, DFG, 절차적/선언적 모델 등)은 그래프·로그 형태다. 이를 **LLM이 처리 가능한 텍스트 포맷**으로 변환해 **자연어 질의→분석/설명→가설 검증**까지 이어지는 파이프라인을 구축하는 것이 목표다.

## 접근
1) **텍스트 추상화(Textual Abstraction)**  
- 예: DFG의 각 간선을 “`A → B (frequency = f, performance = t)`” 형태 문장으로 변환해 핵심 빈도/성능 정보를 보존. 길이 제약(컨텍스트 윈도)에는 저빈도 간선을 생략해 대표성을 유지.  
- `pm4py.llm.abstract_dfg` 등으로 생성한 텍스트를 다양한 표기(→, 자연어 서술, 튜플표현)로도 LLM이 유연하게 해석.

2) **프롬프트 전략(Prompting Strategies)**  
- **Direct Answering**: 추상화 텍스트 + 사용자 질문에 바로 답.  
- **Multi-Prompt Answering**: 질의를 쪼개 순차적으로 맥락을 쌓아가며 답을 정교화.  
- **DB 쿼리 생성**: 원본 로그를 재검증할 **질의 언어/SQL·PQL**을 생성해 가설을 확인.

## 평가 설정
- **LLM**: GPT-4, Google Bard  
- **맥락 시나리오**: 다양한 컨텍스트 길이·형태에서 위 3가지 전략을 비교.

## 핵심 결과
- **프로세스 마이닝 추상물 해석에 견고**: 절차적/선언적 모델 모두에서 의미 있는 이해와 추론.  
- **오브젝트 중심(OC-PM)에서도 강점**: 객체 간 관계를 텍스트로 녹여도 성능이 유지됨.  
- **공정성 평가 가능성**: 편향 지표·규칙을 설명하고 사례 로그에 대해 빠르게 진단하는 잠재력 확인.

## 내 코멘트
- 그래프/로그 → 텍스트 변환으로 **“LLM ↔ 프로세스 마이닝”**의 인터페이스를 깔끔히 정의했다는 점이 실용적.  
- **Direct vs Multi-Prompt vs DB-Query**의 3단 구조는 “설명→추론→검증”을 연결해 **환각(정답 같아 보이나 사실 아님)**을 줄이는 합리적 설계다.  
- 후속 과제: (1) 추상화 손실을 최소화하는 요약 정책, (2) 쿼리 생성의 **정확성·안전성 평가**, (3) 대규모 OC-로그에서의 **스케일성** 검증.

## 링크
- arXiv: https://arxiv.org/abs/2307.12701